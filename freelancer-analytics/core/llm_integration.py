import os
import requests
import logging
import pandas as pd
from dotenv import load_dotenv

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('freelancer_analytics.log')
    ]
)

class Settings:
    def __init__(self):
        load_dotenv()
        self.OPENROUTER_API_KEY = os.getenv("OPENROUTER_API_KEY")
        self.API_URL = os.getenv("API_URL")
        self.DATA_PATH = "/home/fantomas/Documents/archive/freelancer_earnings_bd.csv"
        self.MODEL = "mistralai/mixtral-8x7b-instruct"
        self._validate_settings()
    
    def _validate_settings(self):
        if not self.OPENROUTER_API_KEY:
            raise ValueError("‚ùå API –∫–ª—é—á –Ω–µ –Ω–∞–π–¥–µ–Ω. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ñ–∞–π–ª .env")
        if not self.API_URL:
            raise ValueError("‚ùå API_URL –Ω–µ –Ω–∞–π–¥–µ–Ω. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ñ–∞–π–ª .env")
        if not os.path.exists(self.DATA_PATH):
            raise FileNotFoundError(f"‚ùå –§–∞–π–ª –¥–∞–Ω–Ω—ã—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω: {self.DATA_PATH}")

class DataHandler:
    def __init__(self, data_path):
        self.data_path = data_path
        self._df = None
    
    @property
    def df(self):
        if self._df is None:
            self._load_data()
        return self._df
    
    def _load_data(self):
        try:
            logging.info(f"üì• –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ —Ñ–∞–π–ª–∞: {self.data_path}")
            df = pd.read_csv(self.data_path)

            if 'Earnings_USD' not in df.columns:
                raise ValueError("‚ùå –°—Ç–æ–ª–±–µ—Ü 'Earnings_USD' –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –¥–∞–Ω–Ω—ã—Ö")

            df['Earnings_USD'] = pd.to_numeric(df['Earnings_USD'], errors='coerce')
            df = df.dropna(subset=['Earnings_USD'])

            # –£–¥–∞–ª–∏–º –≤—ã–±—Ä–æ—Å—ã (1-–π –∏ 99-–π –ø–µ—Ä—Ü–µ–Ω—Ç–∏–ª—å)
            q_low, q_high = df['Earnings_USD'].quantile([0.01, 0.99])
            df = df[df['Earnings_USD'].between(q_low, q_high)]

            self._df = df
            logging.info(f"‚úÖ –î–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã. –†–∞–∑–º–µ—Ä: {df.shape}")
        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö: {e}")
            raise

class LLMGenerator:
    def __init__(self, settings):
        self.settings = settings
        self.headers = {
            "Authorization": f"Bearer {self.settings.OPENROUTER_API_KEY}",
            "Content-Type": "application/json"
        }
    
    def generate_response(self, query: str, data_stats: dict) -> str:
        """–ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö —á–µ—Ä–µ–∑ LLM API"""
        prompt = self._build_prompt(query, data_stats)

        try:
            response = requests.post(
                self.settings.API_URL,
                headers=self.headers,
                json={
                    "model": self.settings.MODEL,
                    "messages": [
                        {"role": "system", "content": "–¢—ã –∞–Ω–∞–ª–∏—Ç–∏–∫ –¥–∞–Ω–Ω—ã—Ö. –û—Ç–≤–µ—á–∞–π —Ç–æ—á–Ω–æ –∏ –∫—Ä–∞—Ç–∫–æ."},
                        {"role": "user", "content": prompt}
                    ],
                    "temperature": 0.3,
                    "max_tokens": 300
                },
                timeout=15
            )
            response.raise_for_status()
            return response.json()["choices"][0]["message"]["content"]
        except Exception as e:
            logging.error(f"‚ùå API –æ—à–∏–±–∫–∞: {e}")
            return f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∞–Ω–∞–ª–∏–∑: {e}"
    
    def _build_prompt(self, query: str, data_stats: dict) -> str:
        stats_str = "\n".join(
            f"- {key.replace('_', ' ').capitalize()}: {value:.2f}{' USD' if 'avg' in key or 'difference' in key else ' %' if 'percentage' in key else ''}"
            for key, value in data_stats.items() if isinstance(value, (int, float))
        )
        instruction = "–û—Ç–≤–µ—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å, –∏—Å–ø–æ–ª—å–∑—É—è —Ç–æ–ª—å–∫–æ —ç—Ç–∏ –¥–∞–Ω–Ω—ã–µ. –î–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏–π —É–∫–∞–∂–∏ —Ä–∞–∑–Ω–∏—Ü—É –≤ –¥–æ—Ö–æ–¥–∞—Ö –≤ USD, –µ—Å–ª–∏ –ø—Ä–∏–º–µ–Ω–∏–º–æ."
        return f"""
    –í–æ–ø—Ä–æ—Å: {query}
    –î–∞–Ω–Ω—ã–µ: 
    {stats_str}
    {instruction}
    """.strip()

def main():
    try:
        settings = Settings()
        data_handler = DataHandler(settings.DATA_PATH)
        df = data_handler.df

        stats = {
            'mean': df['Earnings_USD'].mean(),
            'median': df['Earnings_USD'].median(),
            'count': len(df),
            'min': df['Earnings_USD'].min(),
            'max': df['Earnings_USD'].max()
        }

        logging.info(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–æ—Ö–æ–¥–æ–≤: {stats}")

        analyzer = LLMGenerator(settings)
        query = "–ö–∞–∫ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª—è–µ—Ç—Å—è –¥–æ—Ö–æ–¥ —Ñ—Ä–∏–ª–∞–Ω—Å–µ—Ä–æ–≤ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ä–µ–≥–∏–æ–Ω–∞ –ø—Ä–æ–∂–∏–≤–∞–Ω–∏—è?"
        query = "–ö–∞–∫–æ–π –ø—Ä–æ—Ü–µ–Ω—Ç —Ñ—Ä–∏–ª–∞–Ω—Å–µ—Ä–æ–≤, —Å—á–∏—Ç–∞—é—â–∏—Ö —Å–µ–±—è —ç–∫—Å–ø–µ—Ä—Ç–∞–º–∏, –≤—ã–ø–æ–ª–Ω–∏–ª –º–µ–Ω–µ–µ 100 –ø—Ä–æ–µ–∫—Ç–æ–≤?"
        analysis = analyzer.generate_response(query, stats)
        print(f"\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞:\n"
              f"–°—Ä–µ–¥–Ω–∏–π –¥–æ—Ö–æ–¥: {stats['mean']:.2f} USD\n"
              f"–ú–µ–¥–∏–∞–Ω–Ω—ã–π –¥–æ—Ö–æ–¥: {stats['median']:.2f} USD\n"
              f"\nüîç –ê–Ω–∞–ª–∏–∑ –ò–ò:\n{analysis}")

    except Exception as e:
        logging.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ —Ä–∞–±–æ—Ç–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è: {e}")
        print(f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {e}")

if __name__ == "__main__":
    main()

